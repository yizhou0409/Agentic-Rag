# LlamaFactory Configuration for Trajectory Training
# This config focuses on learning from trajectories without caring about final answer correctness

# Model Configuration
model_name: Qwen3-8B-Base
model_path: /scratch/yl9038/models/Qwen3-8B-Base
template: default
finetuning_type: full
quantization_bit: none
quantization_method: bnb
rope_scaling: none
booster: auto
checkpoint_path: null

# Training Configuration
training_stage: Supervised Fine-Tuning
num_train_epochs: 10.0
per_device_train_batch_size: 2
gradient_accumulation_steps: 8
learning_rate: 5e-5
lr_scheduler_type: cosine
warmup_steps: 50
max_grad_norm: 1.0
logging_steps: 5
save_steps: 100
eval_steps: 100
evaluation_strategy: steps
save_strategy: steps
save_total_limit: 2
load_best_model_at_end: true
metric_for_best_model: eval_loss
greater_is_better: false

# Data Configuration
cutoff_len: 2048
max_samples: 100000
val_size: 0.15
dataset_dir: data/llamafactory
dataset:
  - hotpotqa_trajectory_train_5
  - 2wikimultihop_trajectory_train_5

# Advanced Training Options
compute_type: pure_bf16
report_to: none
dataloader_pin_memory: false
remove_unused_columns: false
ddp_timeout: 180000000
dataloader_num_workers: 1

# LoRA Configuration (if using LoRA)
lora_rank: 8
lora_alpha: 16
lora_dropout: 0
lora_target: all

# Memory Optimization
gradient_checkpointing: true
fp16: false
bf16: true

# Output Configuration
output_dir: ./output/llamafactory_sft
push_to_hub: false
hub_model_id: null
hub_strategy: end
hub_token: null
hub_private_repo: false

# Additional Arguments
extra_args:
  optim: adamw_torch
  dataloader_pin_memory: false
  remove_unused_columns: false
  ddp_timeout: 180000000
  dataloader_num_workers: 1 